{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanhaviSoni7/Deep-Learning-Projects/blob/main/Plant_Disease_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FetTCI5V__55"
      },
      "source": [
        "# Set seeds for reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE55h9DVAGKZ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAW_G5fOeOKF"
      },
      "source": [
        "Importing the dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm6Il6-ieSkv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybeGEUBsgkE5"
      },
      "source": [
        "data curation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00LdxEYjgnqh"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bscHxlVOhBn4"
      },
      "outputs": [],
      "source": [
        "kaggle_credentails=json.load(open(\"/content/kaggle (2).json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py7HgijdiFVs"
      },
      "outputs": [],
      "source": [
        "#setup kaggle api key as environment variables\n",
        "os.environ['KAGGLE_USERNAME']=kaggle_credentails[\"username\"]\n",
        "os.environ['KAGGLE_KEY']=kaggle_credentails[\"key\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.system('kaggle datasets download -d jawadali1045/20k-multi-class-crop-disease-images')"
      ],
      "metadata": {
        "id": "_sqKU18lmAcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXPw-2M4jJRT"
      },
      "outputs": [],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0F1cJocktt9"
      },
      "outputs": [],
      "source": [
        "#unzip the downloaded dataset\n",
        "with ZipFile(\"/content/20k-multi-class-crop-disease-images.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3FASgtmmYf1"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-5sgqYant_z"
      },
      "outputs": [],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = \"20k-multi-class-crop-disease-images.zip\"\n",
        "\n",
        "# Extract the zip file to a directory with the same name as the zip file (without extension)\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"20k-multi-class-crop-disease-images\")\n",
        "\n",
        "# List the contents of the extracted directory\n",
        "extracted_dir = \"20k-multi-class-crop-disease-images\"\n",
        "print(\"Contents of extracted directory:\", os.listdir(extracted_dir))\n"
      ],
      "metadata": {
        "id": "7CQY6iGfnPFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IafN4goFl8Iv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# List the contents of the dataset directory\n",
        "dataset_dir = \"20k-multi-class-crop-disease-images\"\n",
        "print(\"Dataset directory contents:\", os.listdir(dataset_dir))\n",
        "\n",
        "# Paths to the Train and Validation directories\n",
        "train_dir = os.path.join(dataset_dir, \"Train\")\n",
        "validation_dir = os.path.join(dataset_dir, \"Validation\")\n",
        "\n",
        "# List the contents of the Train directory\n",
        "print(\"Train directory contents:\", os.listdir(train_dir))\n",
        "\n",
        "# List the contents of the Validation directory\n",
        "print(\"Validation directory contents:\", os.listdir(validation_dir))\n",
        "\n",
        "# Example: List and inspect the first 5 images in the first class of the Train directory\n",
        "first_class_train = os.listdir(train_dir)[0]  # Pick the first class/category in Train\n",
        "first_class_train_path = os.path.join(train_dir, first_class_train)\n",
        "\n",
        "print(f\"Contents of {first_class_train} in Train directory:\", os.listdir(first_class_train_path)[:5])\n",
        "print(f\"Number of images in {first_class_train}:\", len(os.listdir(first_class_train_path)))\n",
        "\n",
        "# Similarly, inspect the first 5 images in the first class of the Validation directory\n",
        "first_class_val = os.listdir(validation_dir)[0]  # Pick the first class/category in Validation\n",
        "first_class_val_path = os.path.join(validation_dir, first_class_val)\n",
        "\n",
        "print(f\"Contents of {first_class_val} in Validation directory:\", os.listdir(first_class_val_path)[:5])\n",
        "print(f\"Number of images in {first_class_val}:\", len(os.listdir(first_class_val_path)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3By1Ggj8vy8k"
      },
      "source": [
        "Number of Classes=38\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znNnfClmv2vU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train_dir = \"20k-multi-class-crop-disease-images/Train\"\n",
        "\n",
        "# List all class directories in the Train folder\n",
        "if os.path.exists(train_dir):\n",
        "    class_names = os.listdir(train_dir)\n",
        "    print(\"Available classes in Train directory:\", class_names)\n",
        "else:\n",
        "    print(f\"Directory {train_dir} does not exist.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoD8-72VxsCr"
      },
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqIkiAV6x49v"
      },
      "outputs": [],
      "source": [
        "#Dataset path\n",
        "base_dir='/content/Train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVZE-UDPyGes"
      },
      "outputs": [],
      "source": [
        "image_path='/content/Train/Army worm/11.jpg'\n",
        "#read the image\n",
        "img= mpimg.imread(image_path)\n",
        "\n",
        "print(img.shape)\n",
        "#display the image\n",
        "plt.imshow(img)\n",
        "plt.axis('off') #turn off axis numbers\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjsAO5I8zdb_"
      },
      "outputs": [],
      "source": [
        "#Image Parameters\n",
        "img_size=224\n",
        "batch_size=32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzdG3_eSzoQG"
      },
      "source": [
        "Train and split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq4AO6klzrE2"
      },
      "outputs": [],
      "source": [
        "#image data generator\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2  # Use 20% of data for validation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yDz-ocSidA-"
      },
      "outputs": [],
      "source": [
        "train_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    subset='training',\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyVUjXkOjlrY"
      },
      "outputs": [],
      "source": [
        "validation_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    subset='validation',\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45N_Ts2dk65V"
      },
      "source": [
        "Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NH6BQ3plAn5"
      },
      "outputs": [],
      "source": [
        "#Model Definition\n",
        "model=models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(img_size,img_size,3)))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(train_generator.num_classes,activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaWmwgEyaWy1"
      },
      "outputs": [],
      "source": [
        "#model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLNpkHmKhcWK"
      },
      "outputs": [],
      "source": [
        "#compile the model\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeyIJL-hi6s2"
      },
      "source": [
        "**Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaVHAyFVXJv0"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mm-0J-alioo9"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUZAAqCRyfK9"
      },
      "source": [
        "**Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-x7I6TDyjUM"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "print(\"Evaluating model....\")\n",
        "val_loss, val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RwP0xDfzn7I"
      },
      "outputs": [],
      "source": [
        "#plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title(\"model Accuracy\")\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train','Test'],loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RD2Oo03Tvrv"
      },
      "source": [
        "**Building a Predictive System**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA51kaJ-T2G0"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Function to load and preprocess the image using Pillow\n",
        "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
        "    # Load the image\n",
        "    img = Image.open(image_path)\n",
        "    # Resize the image\n",
        "    img = img.resize(target_size)\n",
        "    # Convert image to numpy array\n",
        "    img_array = np.array(img)\n",
        "    # Add batch dimension\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    # Scale the image values to [0, 1]\n",
        "    img_array = img_array.astype('float32') / 255.\n",
        "    return img_array\n",
        "\n",
        "# Function to predict the class of an image\n",
        "def predict_image_class(model, image_path, class_indices):\n",
        "    # Load and preprocess the image\n",
        "    preprocessed_img = load_and_preprocess_image(image_path)\n",
        "    # Get model predictions\n",
        "    predictions = model.predict(preprocessed_img)\n",
        "    # Find the index of the highest prediction score\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "    # Map the index to the class name\n",
        "    predicted_class_name = class_indices[predicted_class_index]\n",
        "    return predicted_class_name\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a mapping from class indices to class names\n",
        "class_indices={\n",
        "    v:k for k,v in train_generator.class_indices.items()\n",
        "}"
      ],
      "metadata": {
        "id": "qexuUTEM1izF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices"
      ],
      "metadata": {
        "id": "mD2gikEz39qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"class_indices.json\", \"w\") as json_file:\n",
        "    json.dump(class_indices, json_file)"
      ],
      "metadata": {
        "id": "-37LFkVA40ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image_path = '/content/test_apple_black_rot.jpg'\n",
        "image_path = '/content/corn_northen_leaf_blight_test.jpg'\n",
        "predicted_class_name = predict_image_class(model, image_path, class_indices)\n",
        "print(\"Predicted Class name: \", predicted_class_name)"
      ],
      "metadata": {
        "id": "j7d_gHED57TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the model to google drive**"
      ],
      "metadata": {
        "id": "ehC-aVYnO_7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/My\\ Drive/\n"
      ],
      "metadata": {
        "id": "cJ-mGhvdPFal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/model_name.h5')\n"
      ],
      "metadata": {
        "id": "Ut47sWIzRTGo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}